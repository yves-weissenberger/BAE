{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This notebook is designed to give a basic overview of the functionality of our model.\n",
    "\n",
    "In this package we implement binary decoding of timestamped events. This can be trivially extended to decoding continuous variables. To decode binary variables as described here, the design matrix must contain rows of the timestamps of the two events. In the descriptor of the design matrix, these events should be labelled identically (see the 'dec' varaible in desc [descriptor of the design matrix]; and the corresponding rows of the design matrix in the example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import seaborn\n",
    "clrs = seaborn.color_palette(n_colors=9)\n",
    "seaborn.set(style='ticks',font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mouse_vae import BAE\n",
    "from mouse_vae import dat_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##load video, design matrix and descriptor of design matrix\n",
    "\n",
    "\n",
    "##fill in this path\n",
    "ROOT_PATH = '/path/to/bae'\n",
    "\n",
    "#Load video data\n",
    "video_path = os.path.join(ROOT_PATH,'video_data')\n",
    "video = np.concatenate([np.load(os.path.join(video_path,i)) for i in os.listdir(video_path)])\n",
    "\n",
    "#Design Matrix containing timestamps of task events. One frame is approximately\n",
    "#70ms duration\n",
    "DM =  np.load(os.path.join(ROOT_PATH,'DM.npy'))\n",
    "\n",
    "#Descriptor of Design Matrix specifying what each row of\n",
    "#the design matrix contains. Numbers appended to event types\n",
    "#describe lags\n",
    "desc =  np.load(os.path.join(ROOT_PATH,'desc.npy'))\n",
    "\n",
    "#Index of levels at which stimuli were presented. 1 corresponds to\n",
    "#the loudest stimulus and 99 corresponds to a catch trial\n",
    "allVols =  np.load(os.path.join(ROOT_PATH,'allVols.npy'))#np.load('/home/yves/Documents/Code/mouse_vae/allVols.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalize the video.\n",
    "\n",
    "mu1  = np.mean(video,axis=0)\n",
    "std1 = np.std(video,axis=0)\n",
    "std1[std1<1e-2] = 1e6\n",
    "video = (video-mu1)/std1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add cognitive variables to the design matrix\n",
    "allDM, allDesc = dat_utils.get_full_DM(DM,desc,5,allVols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise elements of the Design Matrix\n",
    "\n",
    "In the visualisations below, events are timestamped according to the time of their entries in the Design Matrix. So for example, bout initiation is not locked to the time of the first lick, but preceding it by several frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "lick_ix = int(np.where(desc=='lickL0')[0])\n",
    "stim_ix = int(np.where(desc=='clicks0')[0])\n",
    "rew_ix = int(np.where(desc=='rews0')[0])\n",
    "bout_ix = int(np.where(desc=='bout_init0')[0])\n",
    "\n",
    "var_names = ['click','rew','lick','bout']\n",
    "for kk,var in enumerate([stim_ix,rew_ix,lick_ix,bout_ix]):\n",
    "    plt.vlines(np.where(DM[var,5000:9000])[0],1.5*kk,1.5*kk+1,label=var_names[kk],color=clrs[kk])\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.xlim(1000,2500)\n",
    "seaborn.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show decision basis regressor relative to other events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here plot\n",
    "\n",
    "lick_ix = int(np.where(allDesc=='lickL0')[0])\n",
    "stim_ix = int(np.where(allDesc=='clicks0')[0])\n",
    "dec0_ix = int(np.where(allDesc=='dec0')[0][1]) #stimulus driven bout\n",
    "dec1_ix = int(np.where(allDesc=='dec0')[0][0]) #spontaneous\n",
    "\n",
    "\n",
    "var_names = ['click','lick','spont-bout','stim-bout']\n",
    "_,(a1,a2) = plt.subplots(1,2, gridspec_kw = {'width_ratios':[3, 2]},figsize=(16,3))\n",
    "\n",
    "\n",
    "for kk,var in enumerate([stim_ix,lick_ix,dec0_ix,dec1_ix]):\n",
    "    a1.vlines(np.where(allDM[var,5000:6000])[0],1.5*kk,1.5*kk+1,label=var_names[kk],color=clrs[kk])\n",
    "a1.set_xlim(0,2000)\n",
    "a1.legend()\n",
    "\n",
    "    \n",
    "for kk,var in enumerate([stim_ix,lick_ix,dec0_ix,dec1_ix]):\n",
    "    a2.vlines(np.where(allDM[var,5000:5100])[0],1.5*kk,1.5*kk+1,label=var_names[kk],color=clrs[kk])\n",
    "\n",
    "seaborn.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "lick_ix = int(np.where(allDesc=='lickL0')[0])\n",
    "stim_ix = int(np.where(allDesc=='clicks0')[0])\n",
    "rew_ix = int(np.where(allDesc=='rew0')[0])\n",
    "att0_ix = int(np.where(allDesc=='att0')[0][1]) #signifies the animal paying attention\n",
    "att1_ix = int(np.where(allDesc=='att0')[0][0]) #signifies the animal is not paying attention\n",
    "\n",
    "\n",
    "\n",
    "var_names = ['click','rew','lick','att0','att1']\n",
    "for kk,var in enumerate([stim_ix,rew_ix,lick_ix,att0_ix,att1_ix]):\n",
    "    plt.vlines(np.where(allDM[var,5000:5500])[0],1.5*kk,1.5*kk+1,label=var_names[kk],color=clrs[kk])\n",
    "\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.xlim(0,700)\n",
    "seaborn.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create an instance of the BAE-model\n",
    "lvm = BAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add data to model instance\n",
    "lvm.add_data(video=video,DM=allDM,descriptor=allDesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change any network. You would like here. To just run a VAE set encode_weight to 0\n",
    "lvm.network_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lvm.network_params['n_epochs'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialise tensorflow variables and functions. Running this function uses our default en-\n",
    "#and decoder networks. Other networks may be used by simply passing a function implementing\n",
    "#some form of network as an argument to this function (see make_encoder and make_decoder in\n",
    "#the model_utils.py for the required structure)\n",
    "lvm.run_tf_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#view network parameters\n",
    "lvm.network_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lvm.estimate_decoding_perf_full_cv(window=[0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit En-and decoder networks\n",
    "lvm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lvm.get_latent_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decoding decision basis. This implementation assumes that evets are discrete\n",
    "lvm.estimate_decoding_perf(decode_ev='dec',window=[0,4],verbose=1,kfp=[5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lvm.fit_encoding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear prediction of latent-states\n",
    "lin_pred_lats = lvm.enc_params.dot(lvm.DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "up = np.percentile(np.concatenate([lvm.lats[:,0],lin_pred_lats[0]]),100)\n",
    "lw = np.percentile(np.concatenate([lvm.lats[:,0],lin_pred_lats[0]]),0)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(lvm.lats[:,0],label='latent state')\n",
    "plt.plot(lin_pred_lats[0],label='linear prediction')\n",
    "plt.ylim(lw,up)\n",
    "plt.xlabel(\"Time (frames)\")\n",
    "plt.ylabel(\"Latent State \\nValue (a.u.)\")\n",
    "plt.locator_params('x',nbins=3)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(lvm.lats[:1000,0])\n",
    "plt.plot(lin_pred_lats[0,:1000])\n",
    "plt.ylim(lw,up)\n",
    "plt.xlabel(\"Time (frames)\")\n",
    "plt.locator_params('x',nbins=3)\n",
    "\n",
    "seaborn.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccs = []\n",
    "for i,j in zip(lin_pred_lats,lvm.lats.T):\n",
    "    ccs.append(np.corrcoef(i,j)[0,1])\n",
    "print('Correlations between predicted and measured latent states is:')\n",
    "for i in ccs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to reconstruct full images from latent states pass an estimate of the latent states \n",
    "#(or the full latent states) to lvm.predictor which returns the decoder network's \n",
    "#prediction of the image\n",
    "reconstructed_images = lvm.sess.run(lvm.predictor, feed_dict={lvm._latents: lin_pred_lats[:,:5].T})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "for kk,im in enumerate(reconstructed_images):\n",
    "    plt.subplot(2,5,kk+1)\n",
    "    plt.imshow(im,cmap='binary_r',vmin=-2,vmax=2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if kk==0:\n",
    "        plt.ylabel(\"Reconstruction\")\n",
    "\n",
    "kk += 1\n",
    "for im in video[:5]:\n",
    "    plt.subplot(2,5,kk+1)\n",
    "    plt.imshow(im,cmap='binary_r',vmin=-5,vmax=5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if kk==5:\n",
    "        plt.ylabel(\"Data\")\n",
    "    kk += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Perform decoding. Returns indices of stimulus driven (click_sel)\n",
    "#and spontaneous bouts (spont_sel), as well as their projection\n",
    "#onto the decoding axis (proj_stim & proj_spont). proj<0\n",
    "#signifies that this bout is decoded as stimulus driven, proj>0\n",
    "#indicates it is classified as spontaneous. Greater distances\n",
    "#from 0 indicate classifier is 'more confident'\n",
    "(click_sel,spont_sel), (proj_stim,proj_spont) = lvm.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(-3,3,num=21)\n",
    "seaborn.distplot(proj_stim,kde=0,bins=bins)\n",
    "seaborn.distplot(proj_spont,kde=0,bins=bins)\n",
    "plt.xlabel(\"Projection onto decoding axis\")\n",
    "plt.ylabel(\"Number of bouts\")\n",
    "seaborn.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [vae]",
   "language": "python",
   "name": "Python [vae]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
